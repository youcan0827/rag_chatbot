#!/usr/bin/env python3
"""
å›½äº¤çœãƒ‡ãƒ¼ã‚¿ RAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ - 100% LangChainå®Ÿè£…
LangChainãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å®Œå…¨ã«æ´»ç”¨ã—ãŸRAGã‚·ã‚¹ãƒ†ãƒ 
"""

import os
from dotenv import load_dotenv
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain.chains import RetrievalQA
import tempfile
import logging

# ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
logging.basicConfig(level=logging.WARNING)

# Hugging Face Tokenizersè­¦å‘Šã‚’æŠ‘åˆ¶
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

load_dotenv()

class LangChainRAGChatbot:
    def __init__(self):
        self.vectorstore = None
        self.qa_chain = None
        self.retriever = None
        
    def initialize(self):
        """LangChainã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("ğŸ”— LangChainã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...")
        
        try:
            # OpenAI API Keyç¢ºèª
            openai_api_key = os.getenv("OPENAI_API_KEY")
            openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
            
            if not openai_api_key and not openrouter_api_key:
                print("âŒ OpenAI ã¾ãŸã¯ OpenRouter APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
            
            # LangChain LLMè¨­å®š
            if openai_api_key:
                print("âœ… OpenAI APIã‚’ä½¿ç”¨ã—ã¾ã™")
                self.llm = ChatOpenAI(
                    model="gpt-3.5-turbo",
                    temperature=0.7,
                    api_key=openai_api_key
                )
            else:
                print("âœ… OpenRouter APIã‚’ä½¿ç”¨ã—ã¾ã™")
                self.llm = ChatOpenAI(
                    model="openai/gpt-3.5-turbo",
                    temperature=0.7,
                    api_key=openrouter_api_key,
                    base_url="https://openrouter.ai/api/v1"
                )
            
            # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°è¨­å®šï¼ˆå¤šè¨€èªå¯¾å¿œï¼‰
            print("ğŸ“¥ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
            self.embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            
            print("âœ… LangChainåˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def load_and_process_pdf(self, pdf_path):
        """LangChainã§PDFã‚’èª­ã¿è¾¼ã‚“ã§å‡¦ç†"""
        print(f"ğŸ“„ LangChainã§PDFã‚’èª­ã¿è¾¼ã¿ä¸­: {pdf_path}")
        
        if not os.path.exists(pdf_path):
            print("âŒ PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        try:
            # LangChain PDFãƒ­ãƒ¼ãƒ€ãƒ¼
            loader = PyPDFLoader(pdf_path)
            documents = loader.load()
            print(f"âœ… {len(documents)}ãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            
            # LangChain ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²å™¨
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200,
                separators=["\\n\\n", "\\n", "ã€‚", "ã€", " ", ""]
            )
            
            # æ–‡æ›¸åˆ†å‰²
            splits = text_splitter.split_documents(documents)
            print(f"âœ… {len(splits)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸ")
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒ³ã‚¯è¡¨ç¤º
            if splits:
                print(f"ğŸ“ ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒ³ã‚¯: {splits[0].page_content[:100]}...")
            
            # LangChain ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä½œæˆï¼ˆChromaï¼‰
            print("ğŸ”„ Chromaãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½œæˆä¸­...")
            
            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ChromaDBä½œæˆ
            with tempfile.TemporaryDirectory() as temp_dir:
                self.vectorstore = Chroma.from_documents(
                    documents=splits,
                    embedding=self.embeddings,
                    persist_directory=temp_dir
                )
                
                # ãƒ¡ãƒ¢ãƒªå†…ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã«æ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
                self.vectorstore = Chroma.from_documents(
                    documents=splits,
                    embedding=self.embeddings
                )
            
            print(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä½œæˆå®Œäº†ï¼ˆ{len(splits)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰")
            
            # LangChain ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ä½œæˆ
            self.retriever = self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 3}
            )
            
            # ãƒ‡ãƒãƒƒã‚°: æ¤œç´¢ãƒ†ã‚¹ãƒˆ
            print("ğŸ” ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢æ¤œç´¢ãƒ†ã‚¹ãƒˆ...")
            test_results = self.retriever.get_relevant_documents("å›½åœŸäº¤é€šçœ")
            print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆæ¤œç´¢çµæœ: {len(test_results)}ä»¶")
            
            return True
            
        except Exception as e:
            print(f"âŒ PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def create_qa_chain(self):
        """LangChain QAãƒã‚§ãƒ¼ãƒ³ä½œæˆ"""
        print("â›“ï¸ LangChain QAãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆä¸­...")
        
        try:
            # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
            template = """ã‚ãªãŸã¯å›½åœŸäº¤é€šçœã®å°‚é–€æ–‡æ›¸ã‚’åˆ†æã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æ–‡æ›¸æƒ…å ±ã«åŸºã¥ã„ã¦ã€è³ªå•ã«æ—¥æœ¬èªã§è©³ã—ãå›ç­”ã—ã¦ãã ã•ã„ã€‚
æ–‡æ›¸ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒãªã„å ´åˆã¯ã€ã€Œæä¾›ã•ã‚ŒãŸæ–‡æ›¸ã«ã¯ãã®æƒ…å ±ãŒå«ã¾ã‚Œã¦ãŠã‚Šã¾ã›ã‚“ã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚

æ–‡æ›¸æƒ…å ±:
{context}

è³ªå•: {question}

å›ç­”:"""

            prompt = ChatPromptTemplate.from_template(template)
            
            # LangChain LCEL (LangChain Expression Language) ãƒã‚§ãƒ¼ãƒ³
            def format_docs(docs):
                return "\\n\\n".join([
                    f"ã€ãƒšãƒ¼ã‚¸{doc.metadata.get('page', 'N/A')}ã€‘\\n{doc.page_content}" 
                    for doc in docs
                ])
            
            self.qa_chain = (
                {"context": self.retriever | format_docs, "question": RunnablePassthrough()}
                | prompt
                | self.llm
                | StrOutputParser()
            )
            
            print("âœ… LangChain QAãƒã‚§ãƒ¼ãƒ³ä½œæˆå®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ QAãƒã‚§ãƒ¼ãƒ³ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def query(self, question):
        """LangChainã§ã‚¯ã‚¨ãƒªå®Ÿè¡Œ"""
        if not self.qa_chain:
            return "âŒ QAãƒã‚§ãƒ¼ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        
        try:
            print("ğŸ” LangChainã§æ¤œç´¢ãƒ»å›ç­”ç”Ÿæˆä¸­...")
            
            # é–¢é€£æ–‡æ›¸å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            relevant_docs = self.retriever.get_relevant_documents(question)
            print(f"ğŸ“Š æ¤œç´¢çµæœ: {len(relevant_docs)}ä»¶ã®é–¢é€£æ–‡æ›¸")
            
            for i, doc in enumerate(relevant_docs, 1):
                page = doc.metadata.get('page', 'N/A')
                print(f"   {i}. ãƒšãƒ¼ã‚¸{page}: {doc.page_content[:100]}...")
            
            # LangChainãƒã‚§ãƒ¼ãƒ³å®Ÿè¡Œ
            response = self.qa_chain.invoke(question)
            return response
            
        except Exception as e:
            return f"âŒ ã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def query_with_source(self, question):
        """ã‚½ãƒ¼ã‚¹æƒ…å ±ä»˜ãã§ã‚¯ã‚¨ãƒªå®Ÿè¡Œ"""
        if not self.retriever:
            return "âŒ ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“", []
        
        try:
            # é–¢é€£æ–‡æ›¸å–å¾—
            relevant_docs = self.retriever.get_relevant_documents(question)
            
            # å›ç­”ç”Ÿæˆ
            answer = self.qa_chain.invoke(question) if self.qa_chain else "QAãƒã‚§ãƒ¼ãƒ³ã‚¨ãƒ©ãƒ¼"
            
            # ã‚½ãƒ¼ã‚¹æƒ…å ±æ•´ç†
            sources = []
            for doc in relevant_docs:
                sources.append({
                    'page': doc.metadata.get('page', 'N/A'),
                    'source': doc.metadata.get('source', 'N/A'),
                    'content': doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content
                })
            
            return answer, sources
            
        except Exception as e:
            return f"âŒ ã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}", []
    
    def chat(self):
        """ãƒãƒ£ãƒƒãƒˆãƒ«ãƒ¼ãƒ—"""
        print("\\n" + "="*60)
        print("ğŸ”— å›½äº¤çœãƒ‡ãƒ¼ã‚¿ RAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ (100% LangChain)")
        print("="*60)
        print("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚çµ‚äº†ã™ã‚‹ã«ã¯ 'quit' ã¾ãŸã¯ 'exit' ã‚’å…¥åŠ›ã€‚")
        print("è©³ç´°æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ 'verbose' ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚ªãƒ³ã«ã§ãã¾ã™ã€‚")
        print("-"*60)
        
        verbose = False
        
        while True:
            try:
                user_input = input("\\nğŸ’¬ è³ªå•: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break
                
                if user_input.lower() == 'verbose':
                    verbose = not verbose
                    status = "ã‚ªãƒ³" if verbose else "ã‚ªãƒ•"
                    print(f"ğŸ“š è©³ç´°è¡¨ç¤º: {status}")
                    continue
                
                if not user_input:
                    continue
                
                if verbose:
                    answer, sources = self.query_with_source(user_input)
                    print(f"\\nğŸ”— å›ç­”: {answer}")
                    
                    if sources:
                        print("\\nğŸ“š å‚ç…§ã—ãŸã‚½ãƒ¼ã‚¹:")
                        print("-" * 40)
                        for i, source in enumerate(sources, 1):
                            print(f"{i}. ãƒšãƒ¼ã‚¸{source['page']} - {source['source']}")
                            print(f"   {source['content']}")
                            print()
                else:
                    answer = self.query(user_input)
                    print(f"\\nğŸ”— å›ç­”: {answer}")
                    
            except KeyboardInterrupt:
                print("\\n\\nğŸ‘‹ ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")

def main():
    print("ğŸ”— å›½äº¤çœãƒ‡ãƒ¼ã‚¿ RAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ - 100% LangChainå®Ÿè£…")
    print("=" * 55)
    
    # APIã‚­ãƒ¼ç¢ºèª
    if not os.getenv("OPENAI_API_KEY") and not os.getenv("OPENROUTER_API_KEY"):
        print("âŒ OpenAI ã¾ãŸã¯ OpenRouter APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("ğŸ’¡ .envãƒ•ã‚¡ã‚¤ãƒ«ã« OPENAI_API_KEY ã¾ãŸã¯ OPENROUTER_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    # ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆåˆæœŸåŒ–
    chatbot = LangChainRAGChatbot()
    
    if not chatbot.initialize():
        return
    
    # PDFèª­ã¿è¾¼ã¿ãƒ»å‡¦ç†
    pdf_path = "/Users/yoshinomukanou/Downloads/å›½äº¤çœã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿/å›½äº¤çœâ‘ .pdf"
    if not chatbot.load_and_process_pdf(pdf_path):
        return
    
    # QAãƒã‚§ãƒ¼ãƒ³ä½œæˆ
    if not chatbot.create_qa_chain():
        return
    
    # ãƒãƒ£ãƒƒãƒˆé–‹å§‹
    chatbot.chat()

if __name__ == "__main__":
    main()